{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install tensorflow","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install scipy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install matplotlib","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import math\nimport json\nimport random\nimport pprint\nimport scipy.misc\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nimport os\nimport time\n\nfrom tensorflow.python.framework import ops\nfrom tensorflow.keras import initializers\nimport matplotlib.patches as patches\n\nplt.style.use('dark_background')\n","metadata":{"execution":{"iopub.status.busy":"2023-09-29T16:56:16.660248Z","iopub.execute_input":"2023-09-29T16:56:16.660570Z","iopub.status.idle":"2023-09-29T16:56:16.666039Z","shell.execute_reply.started":"2023-09-29T16:56:16.660544Z","shell.execute_reply":"2023-09-29T16:56:16.665075Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# !pip install tensorflow","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from __future__ import division\n# It ensures that the division operator (/) behaves like true division by default,\n# even when dividing integers, similar to Python 3.x behavior.\nimport math\nimport json\nimport random\nimport pprint\n## pretty print\nimport scipy.misc\nimport numpy as np\n# from time import gmtime, strftime\n# from six.moves import xrange\n## Commented out by Aswin\n# import PIL\n# from PIL import Image\n# from PIL import ImageFont, ImageDraw\n# from PIL import Image\n## Commented out by Aswin\nimport matplotlib.pyplot as plt\nimport keras\nimport os\n# import imageio\n## Commented out by Aswin\n\n\nimport os\nimport time\nimport math\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\nimport math\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.python.framework import ops\nfrom tensorflow.keras import initializers\nimport matplotlib.patches as patches\nfrom matplotlib.patches import Patch\nplt.style.use('dark_background')\n","metadata":{"id":"465QfOrJmk6M","execution":{"iopub.status.busy":"2023-09-29T16:56:21.674126Z","iopub.execute_input":"2023-09-29T16:56:21.674454Z","iopub.status.idle":"2023-09-29T16:56:21.681391Z","shell.execute_reply.started":"2023-09-29T16:56:21.674427Z","shell.execute_reply":"2023-09-29T16:56:21.680446Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# os.environ['CUDA_VISIBLE_DEVICES']='1'\n# config = tf.compat.v1.ConfigProto()\n# config.gpu_options.per_process_gpu_memory_fraction = 0.5\n# session = tf.compat.v1.Session(config=config)","metadata":{"id":"MuNDKWQc_nQk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def convert_to_cxywh(data):\n\n    bboxes = data[...,0:4]\n    labels = data[...,4:]\n    mask = np.zeros_like(data[...,3:4])\n    labels = np.concatenate((mask,labels), axis = 2)\n    labels = np.argmax(labels,axis=2)\n    class_info = np.expand_dims(labels, axis=2)\n    cxywh = np.concatenate((class_info,bboxes), axis = 2)\n    cxywh[..., 1] = cxywh[..., 1] - cxywh[..., 3]/2\n    cxywh[..., 2] = cxywh[..., 2] - cxywh[..., 4]/2\n    return cxywh\n\ndef generate_colors(class_names = None,n_class=50):\n            cmap = [\"\",\"#dc143c\",\"#ffff00\",\"#00ff00\",\"#ff00ff\",\"#1e90ff\",\"#fff5ee\",\n                    \"#00ffff\",\"#8b008b\",\"#ff4500\",\"#8b4513\",\"#808000\",\"#483d8b\",\n                    \"#008000\",\"#000080\",\"#9acd32\",\"#ffa500\",\"#ba55d3\",\"#00fa9a\",\n                    \"#dc143c\",\"#0000ff\",\"#f08080\",\"#f0e68c\",\"#dda0dd\",\"#ff1493\"]\n            colors = dict()\n            if class_names == None:\n                class_names = []\n                for i in range(n_class):\n                    class_names.append('class'+str(i+1))\n            ## If you dont give this function class names, it will create classes like class1,class2,...\n            for i in range(n_class):\n                ## default number of classes is assumed to be 50\n                colors[class_names[i]] = cmap[i]\n            return colors\n\n# class_names = ['None', 'Text', 'Title', 'List', 'Table','Figure']\n## RPLAN Change\nclass_names = ['None', 'Room1', 'Room2', 'Room3', 'Room4','Room5']\n\n\n## These are the class_names which means the types of classes we are dealing with in this GAN project\n## These have to be changed to fit our situation\n## The generate_colors function assigns colors to each category in the class_names list and returns a dictionary\ncolors = generate_colors(n_class=6 , class_names=class_names)\n\ndef plot_layouts(pred,colors,class_names,path=\"\"):\n    height=20\n    width=12\n    # Set the height and width of the overall figure.\n\n    fig= plt.figure(figsize=(width,height), dpi=40 ,facecolor=(0,0,0))\n    height_ratio = [0.25,1,1,1,1]\n    # Specify the height ratios for the subplot grid.\n\n    grid= plt.GridSpec(5,4,hspace=0.05,wspace=0.05, height_ratios = height_ratio, left=0.02,right=0.98,top=0.98,bottom=0.02)\n    # Create a grid of subplots.\n\n    index = 0\n    ## index variable keeps track of subplots positions\n\n    # Create a legend to represent class colors.\n    legend = []\n    ax = fig.add_subplot(grid[index : index+4])\n    index += 4\n\n    # Loop through the class names and create legend entries with colors.\n    for i in range(1,6):\n        legend.append(Patch(facecolor=colors[class_names[i]]+\"30\",\n                            edgecolor=colors[class_names[i]],\n                            label= class_names[i]))\n\n    ax.legend(handles=legend, ncol=3,loc=8, fontsize=25, facecolor=(0,0,0))\n    ax.axis('off')\n\n    \n    for i in range(16):\n        ax   = fig.add_subplot(grid[index])\n        index += 1\n\n        data = pred[i]\n\n        ## creating a black rectange for the background of the image\n        rect1 = patches.Rectangle((0,0),180,240)\n        rect1.set_color((0,0,0,1))\n        ax.add_patch(rect1)\n\n        # Loop through bounding boxes and draw rectangles for each prediction.\n        for box in data:\n\n            c,x,y,w,h = box\n            if c==0:\n                continue\n            ## c=0 means that particular room does not exist. So you can move on\n            x = x*180\n            y = y*240\n            w = w*180\n            h = h*240\n            \n            ##Create a rectangle patch with the class color.\n            rect = patches.Rectangle((x,y),w,h,linewidth=4)\n            rect.set_color(colors[class_names[int(c)]]+\"00\")\n            rect.set_linestyle('-')\n            rect.set_edgecolor(colors[class_names[int(c)]])\n            ax.add_patch(rect)\n        ax.plot()\n        ax.set_facecolor((0,0,0))\n\n        # Customize the appearance of subplot spines (axes borders).\n\n        for spine in ax.spines.values():\n            spine.set_edgecolor('green')\n            spine.set_linewidth(2)\n        \n        ## removing the x-axis and y-axis ticks\n        ax.invert_yaxis()\n        ax.set_xticks([])\n        ax.set_yticks([])\n        \n    plt.savefig(path, facecolor=(0,0,0))\n\n","metadata":{"id":"7M25OPQ6_nQl","execution":{"iopub.status.busy":"2023-09-29T16:56:58.799132Z","iopub.execute_input":"2023-09-29T16:56:58.799454Z","iopub.status.idle":"2023-09-29T16:56:58.814657Z","shell.execute_reply.started":"2023-09-29T16:56:58.799428Z","shell.execute_reply":"2023-09-29T16:56:58.813662Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef layout_bbox(final_pred, output_height, output_width):\n    final_pred = tf.reshape(final_pred, [64, 9, 9])\n    # Reshape the final prediction tensor to [batch_size=64, grid_size=9x9].\n\n    # Slice the tensor to separate bounding box regression and class probability.\n    bbox_reg = tf.slice(final_pred, [0, 0, 0], [-1, -1, 4])\n    cls_prob = tf.slice(final_pred, [0, 0, 4], [-1, -1, 5])\n\n    # Reshape the bounding box regression tensor to [batch_size=64, grid_size=9x4].\n    bbox_reg = tf.reshape(bbox_reg, [64, 9, 4])\n\n    # Compute the x, y, width, and height components of bounding boxes.\n    x_c = tf.slice(bbox_reg, [0, 0, 0], [-1, -1, 1]) * output_width\n    y_c = tf.slice(bbox_reg, [0, 0, 1], [-1, -1, 1]) * output_height\n    w   = tf.slice(bbox_reg, [0, 0, 2], [-1, -1, 1]) * output_width\n    h   = tf.slice(bbox_reg, [0, 0, 3], [-1, -1, 1]) * output_height\n\n    # Calculate the coordinates of the four corners of bounding boxes.\n    ## x1,y1 is the bottom left and x2,y2 is the top right corner\n    x1 = x_c - 0.5*w\n    x2 = x_c + 0.5*w\n    y1 = y_c - 0.5*h\n    y2 = y_c + 0.5*h\n\n    # Create grids of x and y coordinates.\n    xt = tf.reshape(tf.range(output_width, dtype=tf.float32), [1, 1, 1, -1])\n    xt = tf.reshape(tf.tile(xt, [64, 9, output_height, 1]), [64, 9, -1])\n    yt = tf.reshape(tf.range(output_height, dtype=tf.float32), [1, 1, -1, 1])\n    yt = tf.reshape(tf.tile(yt, [64, 9, 1, output_width]), [64, 9, -1])\n\n    \"\"\"\n    tf.range(output_width, dtype=tf.float32) creates a 1D tensor of sequential numbers from 0 to output_width - 1. This represents the x-coordinates of a grid.\n    tf.reshape(..., [1, 1, 1, -1]) reshapes the 1D tensor into a 4D tensor with one channel.\n    tf.tile(xt, [64, 9, output_height, 1]) replicates the x-coordinate grid along different dimensions to match the required shape.\n    The same procedure is applied to create a y-coordinate grid, yt.\n    \"\"\"\n\n    # Calculate the differences between grid coordinates and bounding box coordinates.\n    x1_diff = tf.reshape(xt-x1, [64, 9, output_height, output_width, 1])\n    y1_diff = tf.reshape(yt-y1, [64, 9, output_height, output_width, 1])\n    x2_diff = tf.reshape(x2-xt, [64, 9, output_height, output_width, 1])\n    y2_diff = tf.reshape(y2-yt, [64, 9, output_height, output_width, 1])\n\n    \"\"\"\n    xt, yt are the grid coordinates created in the previous step.\n    x1_diff represents the difference between each x-coordinate in the grid (xt) and the left x-coordinate of the bounding boxes (x1).\n    y1_diff represents the difference between each y-coordinate in the grid (yt) and the top y-coordinate of the bounding boxes (y1).\n    x2_diff represents the difference between the right x-coordinate of the bounding boxes (x2) and each x-coordinate in the grid (xt).\n    y2_diff represents the difference between the bottom y-coordinate of the bounding boxes (y2) and each y-coordinate in the grid (yt).\n    \"\"\"\n\n    # Compute overlapping regions between bounding boxes and grid lines.\n    x1_line = tf.nn.relu(1.0 - tf.abs(x1_diff)) * tf.minimum(tf.nn.relu(y1_diff), 1.0) * tf.minimum(tf.nn.relu(y2_diff), 1.0)\n    x2_line = tf.nn.relu(1.0 - tf.abs(x2_diff)) * tf.minimum(tf.nn.relu(y1_diff), 1.0) * tf.minimum(tf.nn.relu(y2_diff), 1.0)\n    y1_line = tf.nn.relu(1.0 - tf.abs(y1_diff)) * tf.minimum(tf.nn.relu(x1_diff), 1.0) * tf.minimum(tf.nn.relu(x2_diff), 1.0)\n    y2_line = tf.nn.relu(1.0 - tf.abs(y2_diff)) * tf.minimum(tf.nn.relu(x1_diff), 1.0) * tf.minimum(tf.nn.relu(x2_diff), 1.0)\n\n    # Find the maximum value along the last axis of the four line tensors.\n    xy_max = tf.reduce_max(tf.concat([x1_line, x2_line, y1_line, y2_line], axis=-1), axis=-1, keepdims=True)\n\n    # Multiply the maximum overlap with class probabilities and reduce along the second axis.\n    spatial_prob = tf.multiply(tf.tile(xy_max, [1, 1, 1, 1, 5]), tf.reshape(cls_prob, [64, 9, 1, 1, 5]))\n    spatial_prob_max = tf.reduce_max(spatial_prob, axis=1, keepdims=False)\n\n    return spatial_prob_max","metadata":{"id":"33Goyoyzn_6y","execution":{"iopub.status.busy":"2023-09-29T16:57:01.923279Z","iopub.execute_input":"2023-09-29T16:57:01.923614Z","iopub.status.idle":"2023-09-29T16:57:01.937701Z","shell.execute_reply.started":"2023-09-29T16:57:01.923586Z","shell.execute_reply":"2023-09-29T16:57:01.936657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class RelationModule(tf.keras.Model):\n    ## USED AS ATTENTION MODULE BETWEEN LAYERS\n    def __init__(self, channels=128,output_dim=128,key_dim=128,**kwargs):\n        ## constructor to initialise the parameters of this class\n        super(RelationModule, self).__init__(**kwargs)\n        self.key_dim    = channels\n        self.output_dim = channels\n        self.channels   = channels\n        self.key   = tf.keras.layers.Conv2D(output_dim, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.query = tf.keras.layers.Conv2D(key_dim, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.value = tf.keras.layers.Conv2D(key_dim, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.projection = tf.keras.layers.Conv2D(channels, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        # key,query,value define  the input\n        # projection defines the output\n        # key, query, projection and value together define the convolutional layers within the module\n    \n    def call(self, inputs):\n        # defines forward pass of the model\n        ## takes var 'inputs' which is an input tensor\n        f_k = tf.reshape( self.key(inputs),[inputs.shape[0],inputs.shape[1]*inputs.shape[2],self.key_dim])\n        # f_k here stands for key\n        # Applies the key convolutional layer to the input and reshapes the result into a tensor with shape [batch_size, flattened_shape, key_dim].\n        f_q = tf.reshape(self.query(inputs),[inputs.shape[0],inputs.shape[1]*inputs.shape[2],self.key_dim])\n        f_q = tf.transpose(f_q,perm=[0,2,1])\n        # q here stands for query convolutional layer\n        # Applies the query convolutional layer to the input and reshapes the result similarly.\n        # Transposes the f_q tensor to change its shape to [batch_size, self.key_dim, flattened_shape].\n        f_v = tf.reshape(self.value(inputs),[inputs.shape[0],inputs.shape[1]*inputs.shape[2],self.output_dim])\n        # v here stands for value convolutional layer\n        # Applies the value convolutional layer to the input and reshapes the result into a tensor with shape [batch_size, flattened_shape, output_dim].\n        \n        \n        attention_weight = tf.matmul(f_k,f_q)/(inputs.shape[1]*inputs.shape[2])\n        out = tf.matmul(tf.transpose(attention_weight,perm=[0,2,1]),f_v)\n        out = tf.reshape(out,[inputs.shape[0],inputs.shape[1],inputs.shape[2],self.output_dim])\n        out = self.projection(out)\n        return out\n\nclass Discriminator(tf.keras.Model):\n    def __init__(self, n_filters=32, n_hidden=128, layout_dim=(28,28),render=layout_bbox,**kwargs):\n        super(Discriminator, self).__init__(**kwargs)\n        self.layout_dim = layout_dim\n        self.render = render\n        self.act   = tf.keras.layers.LeakyReLU(alpha = 0.2)\n        self.conv1 = tf.keras.layers.Conv2D(32, (5,5),input_shape=layout_dim, strides=(2, 2), padding='valid', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn1   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n\n        self.conv2 = tf.keras.layers.Conv2D(32*2, (5,5), strides=(2, 2), padding='valid', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn2   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n\n        self.flatten = tf.keras.layers.Flatten()\n        self.fc1   = tf.keras.layers.Dense(512, kernel_initializer=initializers.RandomNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn3   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.fc2   = tf.keras.layers.Dense(1, kernel_initializer=initializers.RandomNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n\n    def call(self, inputs):\n        x = self.render(inputs, self.layout_dim[0], self.layout_dim[1])\n        x = self.act(self.bn1(self.conv1(x)))\n        x = self.act(self.bn2(self.conv2(x)))\n        x = self.flatten(x)\n        x = self.act(self.bn3(self.fc1(x)))\n        out = self.fc2(x)\n        return out\n\nclass Generator(tf.keras.Model):\n    def __init__(self, n_filters=128,output_dim=2,n_component=128,n_class=1,include_probability=False,**kwargs):\n        super(Generator, self).__init__(**kwargs)\n        self.n_filters   = n_filters\n        self.output_dim  = output_dim\n        self.n_component = n_component\n        self.n_class = n_class\n        self.include_probability = include_probability\n\n        self.act   = tf.keras.layers.ReLU()\n        # Use the ReLU function for activation here\n        self.conv1_1 = tf.keras.layers.Conv2D(n_filters//4, (1,1),input_shape=(self.n_component,1,self.n_class+self.output_dim), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        # This line creates a convolutional layer (conv1_1) with the specified parameters, including the number of filters, kernel size, and initialization methods.\n        self.bn1_1   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        # This adds batch normalization after conv1_1 to normalize the activations and stabilize training.\n        self.conv1_2 = tf.keras.layers.Conv2D(n_filters//16, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn1_2   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.conv1_3 = tf.keras.layers.Conv2D(n_filters//16, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn1_3   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.conv1_4 = tf.keras.layers.Conv2D(n_filters//4, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn1_4   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        ## The process of creating a convolutional layer followed by a batch normalization layer is repeated in the above code\n        \n\n        self.relation1 = RelationModule(channels=n_filters//4,output_dim=n_filters//4,key_dim=n_filters//4)\n        self.relation2 = RelationModule(channels=n_filters//4,output_dim=n_filters//4,key_dim=n_filters//4)\n        self.relation3 = RelationModule(channels=n_filters,output_dim=n_filters,key_dim=n_filters)\n        self.relation4 = RelationModule(channels=n_filters,output_dim=n_filters,key_dim=n_filters)\n        # RelationModule is a custom user defined class. We use it here\n\n        self.bn_x1   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.bn_x2   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.bn_x3   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.bn_x4   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n\n        self.bn_x5   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.bn_x6   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.bn_x7   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.bn_x8   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n\n        self.conv2_1 = tf.keras.layers.Conv2D(n_filters, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn2_1   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.conv2_2 = tf.keras.layers.Conv2D(n_filters//4, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn2_2   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.conv2_3 = tf.keras.layers.Conv2D(n_filters//4, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn2_3   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.conv2_4 = tf.keras.layers.Conv2D(n_filters, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.bn2_4   = tf.keras.layers.BatchNormalization(epsilon=1e-5, momentum = 0.9)\n        self.geometric_param = tf.keras.layers.Conv2D(output_dim, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.001, mean = 0.0),bias_initializer=initializers.constant(0.0))\n        self.class_score = tf.keras.layers.Conv2D(n_class, (1,1), strides=(1, 1), padding='same', kernel_initializer=initializers.TruncatedNormal(stddev=0.02, mean = 0.0),bias_initializer=initializers.constant(0.0))\n\n    def call(self, x):\n        x = tf.reshape(x, [x.shape[0], self.n_component, 1, self.n_class+self.output_dim])\n        h1_0 = self.bn1_1(self.conv1_1(x))\n        h1_1 = self.act(self.bn1_2(self.conv1_2(x)))\n        h1_2 = self.act(self.bn1_3(self.conv1_3(h1_1)))\n        h1_3 = self.bn1_4(self.conv1_4(h1_2))\n        embedding = self.act(tf.add(h1_0,h1_3))\n        embedding = tf.reshape(embedding,[x.shape[0],self.n_component,1,256])\n\n        context = self.act(self.bn_x2(tf.add(embedding,self.bn_x1(self.relation1(embedding)))))\n        context = self.act(self.bn_x4(tf.add(context,self.bn_x3(self.relation2(context)))))\n\n        h2_0 = self.bn2_1(self.conv2_1(context))\n        h2_1 = self.act(self.bn2_2(self.conv2_2(h2_0)))\n        h2_2 = self.act(self.bn2_3(self.conv2_3(h2_1)))\n        h2_3 = self.bn2_4(self.conv2_4(h2_2))\n        decoded = self.act(tf.add(h2_0,h2_3))\n\n        decoded = self.act(self.bn_x6(tf.add(decoded,self.bn_x5(self.relation3(decoded)))))\n        decoded = self.act(self.bn_x8(tf.add(decoded,self.bn_x7(self.relation4(decoded)))))\n\n        out = self.geometric_param(decoded)\n        out = tf.sigmoid(tf.reshape(out,[-1,self.n_component,self.output_dim]))\n\n        cls_score = self.class_score(decoded)\n        cls_prob  = tf.sigmoid(tf.reshape(cls_score,[-1,self.n_component,self.n_class]))\n        final_pred = tf.concat([out,cls_prob],axis=-1)\n        return final_pred\n","metadata":{"id":"XRHAkirJ_nQp","execution":{"iopub.status.busy":"2023-09-29T16:57:13.013660Z","iopub.execute_input":"2023-09-29T16:57:13.014210Z","iopub.status.idle":"2023-09-29T16:57:13.047190Z","shell.execute_reply.started":"2023-09-29T16:57:13.014180Z","shell.execute_reply":"2023-09-29T16:57:13.046248Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"This Python code defines three classes: `RelationModule`, `Discriminator`, and `Generator`. I'll explain each of these classes and their functions individually and then provide an overall explanation of what the entire code does.\n\n### `RelationModule` Class\nThis class appears to be a module for handling relations between data points. It's primarily used for processing data in a convolutional neural network (CNN) architecture.\n\n#### `__init__(self, channels=128, output_dim=128, key_dim=128, **kwargs)`\n- Constructor method that initializes the attributes of the class.\n- Parameters:\n  - `channels`: The number of channels for the data.\n  - `output_dim`: The dimensionality of the output data.\n  - `key_dim`: The dimensionality of the key data.\n  - `**kwargs`: Additional keyword arguments passed to the parent class constructor.\n- It creates several layers (Conv2D layers) for processing data.\n\n#### `call(self, inputs)`\n- The method responsible for processing inputs and performing computations.\n- It reshapes the input tensor and applies convolution operations to compute attention weights.\n- Then, it performs matrix multiplications to calculate the output.\n- Finally, it reshapes and projects the output before returning it.\n\n### `Discriminator` Class\nThis class represents a discriminator model typically used in adversarial networks like GANs (Generative Adversarial Networks).\n\n#### `__init__(self, n_filters=32, n_hidden=128, layout_dim=(28, 28), render=layout_bbox, **kwargs)`\n- Constructor method that initializes the attributes of the class.\n- Parameters:\n  - `n_filters`: The number of filters in convolutional layers.\n  - `n_hidden`: The number of hidden units in fully connected layers.\n  - `layout_dim`: Dimensions of the layout data.\n  - `render`: A function used for rendering layout data.\n  - `**kwargs`: Additional keyword arguments passed to the parent class constructor.\n- It creates several layers (Conv2D, BatchNormalization, and Dense layers) for processing data.\n\n#### `call(self, inputs)`\n- The method responsible for processing inputs and performing computations.\n- It renders the layout using the provided `render` function.\n- Then, it applies convolution, batch normalization, and activation functions to compute the output.\n- Finally, it returns the output.\n\n### `Generator` Class\nThis class represents a generator model, often used alongside a discriminator in GANs.\n\n#### `__init__(self, n_filters=128, output_dim=2, n_component=128, n_class=1, include_probability=False, **kwargs)`\n- Constructor method that initializes the attributes of the class.\n- Parameters:\n  - `n_filters`: The number of filters in convolutional layers.\n  - `output_dim`: The dimensionality of the output data.\n  - `n_component`: The number of components.\n  - `n_class`: The number of classes.\n  - `include_probability`: A boolean indicating whether to include probability in the output.\n  - `**kwargs`: Additional keyword arguments passed to the parent class constructor.\n- It creates several layers (Conv2D, BatchNormalization, and Dense layers) for processing data.\n\n#### `call(self, x)`\n- The method responsible for processing inputs and performing computations.\n- It reshapes the input tensor and applies convolution operations.\n- The model includes a `RelationModule` that processes the input.\n- It then further processes the data through convolution, batch normalization, and activation functions.\n- The final output includes geometric parameters and class probabilities concatenated together.\n\n### Overall Functionality\nThe code defines three classes that can be used to build neural network models for various tasks. These classes are building blocks for neural network architectures used in machine learning and deep learning tasks. The `RelationModule` class seems to focus on processing attention-like mechanisms, while the `Discriminator` and `Generator` classes appear to be part of a GAN-based architecture, where the discriminator assesses the realism of generated data, and the generator produces data to try and fool the discriminator. The exact purpose of this code depends on how these classes are used in a larger context, as this code provides the architecture and computations, but it doesn't specify the broader task or training process.","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Download it from \"https://drive.google.com/file/d/1YQKyASvGDNUTJnE1x-Q2ZhhiY0VFj7oZ/view?usp=sharing\"\ndataset_path = r\"/kaggle/input/converted-rplan-to-publay/array_from_list.npy\"\n#provide directory for storing predictions\nsam_dir = r\"/kaggle/working\"\n","metadata":{"id":"iI_YxD3zqeO4","execution":{"iopub.status.busy":"2023-09-29T16:57:19.792214Z","iopub.execute_input":"2023-09-29T16:57:19.793370Z","iopub.status.idle":"2023-09-29T16:57:19.798354Z","shell.execute_reply.started":"2023-09-29T16:57:19.793327Z","shell.execute_reply":"2023-09-29T16:57:19.796987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfrom __future__ import division\nimport os\nimport time\nimport math\nfrom glob import glob\nimport tensorflow as tf\nimport numpy as np\nimport random\nfrom matplotlib.patches import Patch\n\nimport matplotlib.pyplot as plt \n\nclass LayoutGAN(object):\n    # def __init__(self, geometric_dim=2, n_class=1, batch_size=64, n_component=128, layout_dim=(28,28),d_lr=1e-5,g_lr=1e-5,update_ratio=2,clip_value=0.1, dataset_name='default', dataset_path='./data/pre_data_cls.npy', checkpoint_dir=None, sample_dir=None):\n    ## Changed by Aswin\n    def __init__(self, geometric_dim=2, n_class=1, batch_size=64, n_component=128, layout_dim=(28,28),d_lr=2e-5,g_lr=2e-5,update_ratio=2,clip_value=0.1, dataset_name='default', dataset_path='./data/pre_data_cls.npy', checkpoint_dir=None, sample_dir=None):\n        self.batch_size = batch_size\n        self.n_component = n_component\n        self.n_class    = n_class\n        self.geometric_dim = geometric_dim\n        self.layout_dim = layout_dim\n        self.dataset_name  = dataset_name\n        self.checkpoint_dir = checkpoint_dir\n        self.data = np.load(dataset_path)\n        self.build_model(d_lr,g_lr)\n        self.sample_dir = sample_dir\n        self.update_ratio=update_ratio\n        self.clip_value = clip_value\n        # self.epochs = 50\n        self.epochs=5\n        ## Changed by Aswin\n\n    def build_model(self,d_lr,g_lr):\n        self.G = self.build_generator()\n        self.D = self.build_discriminator()\n        epoch_step = len(self.data) // self.batch_size \n        # dlr = tf.keras.optimizers.schedules.ExponentialDecay(d_lr,decay_steps=20*epoch_step,decay_rate=0.1,staircase=True)\n        dlr = tf.keras.optimizers.schedules.ExponentialDecay(d_lr,decay_steps=20*epoch_step,decay_rate=0.2,staircase=True)\n        self.d_opt = tf.keras.optimizers.Adam(dlr)\n        self.g_opt = tf.keras.optimizers.Adam(dlr)\n\n\n    def step(self,real_data,noise,training=True,step=0):\n        with tf.GradientTape() as disc_tape:\n            disc_loss = self.discriminator_loss(real_data, noise)\n            if(training):\n                gradients_of_discriminator = disc_tape.gradient(disc_loss, self.D.trainable_variables)\n                self.d_opt.apply_gradients(zip(gradients_of_discriminator, self.D.trainable_variables))\n\n        for i in range (self.update_ratio):\n            with  tf.GradientTape() as gen_tape:\n                gen_loss = self.generator_loss(noise)\n                if(training):\n                    gradients_of_generator = gen_tape.gradient(gen_loss, self.G.trainable_variables)\n                    self.g_opt.apply_gradients(zip(gradients_of_generator, self.G.trainable_variables))\n\n        return gen_loss, disc_loss              \n\n    def train(self):\n        epoch_step = len(self.data) // self.batch_size    \n        sample = self.data[0:self.batch_size]\n        sample_inputs = np.array(sample).astype(np.float32) \n        sample_z_bbox = np.random.normal(0.5, 0.15, (self.batch_size, 9, 4))\n        sample_z_cls = np.identity(5)[np.random.randint(5, size=(self.batch_size, 9))]\n        sample_z = np.concatenate([sample_z_bbox, sample_z_cls], axis=-1)\n        counter = 1\n        start_time = time.time()\n\n        for epoch in range(self.epochs):\n            np.random.shuffle(self.data)\n            batch_idxs = len(self.data) // self.batch_size\n\n            for idx in range(0, batch_idxs):\n                batch = self.data[idx*self.batch_size:(idx+1)*self.batch_size]\n                batch_images = np.array(batch).astype(np.float32)\n\n                batch_z_bbox = np.random.normal(0.5, 0.15, (self.batch_size, 9, 4))\n                batch_z_cls = np.identity(5)[np.random.randint(5, size=(self.batch_size, 9))]\n                batch_z = np.concatenate([batch_z_bbox, batch_z_cls], axis=-1)    \n\n                g_loss, d_loss = self.step(batch_images,batch_z,step=idx)\n                counter += 1\n                if np.mod(counter, 1) == 0:\n                    ## Changed by Aswin\n                    \n                    # current_decayed_lr = self.d_opt._decayed_lr(tf.float32).numpy()\n                    # print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, lr:%.3E, d_loss: %.4f, g_loss: %.4f\" \\\n                    #     % (epoch, idx, batch_idxs, time.time()-start_time, current_decayed_lr, d_loss, g_loss))\n                    current_learning_rate = self.d_opt.learning_rate.numpy()\n                    print(\"Epoch: [%2d] [%4d/%4d] time: %4.4f, lr:%.3E, d_loss: %.4f, g_loss: %.4f\" \\\n                        % (epoch, idx, batch_idxs, time.time()-start_time, current_learning_rate, d_loss, g_loss))\n\n\n                if np.mod(counter, 1) == 0:\n                    ## Changed by Aswin\n                    G_samples = self.G(sample_z, training = False)\n                    path = '{}/train_{:02d}_{:04d}_{:2.4f}_{:2.4f}.jpg'.format(self.sample_dir, epoch, idx,d_loss, g_loss)                \n                    change = convert_to_cxywh(np.array(G_samples))\n                    plot_layouts(change,colors=colors,class_names=class_names,path = path)\n                    g_loss, d_loss = self.step(sample_inputs,sample_z,training=False)\n                    print(\"[Sample] d_loss: %.8f, g_loss: %.8f\" % (d_loss, g_loss)) \n        \n    def render(self):\n        pass\n\n    def build_discriminator(self): \n        return Discriminator(layout_dim=self.layout_dim,render=layout_bbox)\n        \n    def build_generator(self):\n        return Generator(n_filters=1024,output_dim=self.geometric_dim,n_component=self.n_component,n_class=self.n_class)\n\n    def generator_loss(self, z):\n        x = self.G(z, training=True) \n        fake_score = self.D(x, training=True)\n        g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = fake_score, labels=tf.ones_like(tf.sigmoid(fake_score))))\n        return g_loss\n\n    def discriminator_loss(self, x, z):\n        x_fake = self.G(z, training=True)\n        true_score = self.D(x, training=True)\n        fake_score = self.D(x_fake, training=True)\n        d_loss_real = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = true_score, labels=tf.ones_like(tf.sigmoid(true_score))))\n        d_loss_fake = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits = fake_score, labels=tf.zeros_like(tf.sigmoid(fake_score))))\n        d_loss = d_loss_real + d_loss_fake\n        return d_loss\n\nif __name__ == '__main__':\n    batch_size=64\n    n_component=9\n    n_class=5\n    geometric_dim=4\n    gan = LayoutGAN(batch_size=batch_size,n_component=n_component,\n                    n_class=n_class,layout_dim=(60,40),\n                    geometric_dim=geometric_dim,\n                    sample_dir = sam_dir, \n                    dataset_path=dataset_path)\n    \n    gan.train()\n    ","metadata":{"id":"zAWa29sCoIHS","outputId":"c25c74c6-61ee-4f6d-dbd8-7112e1bbc98d","execution":{"iopub.status.busy":"2023-09-29T16:57:22.453930Z","iopub.execute_input":"2023-09-29T16:57:22.454261Z","iopub.status.idle":"2023-09-29T17:08:22.688287Z","shell.execute_reply.started":"2023-09-29T16:57:22.454233Z","shell.execute_reply":"2023-09-29T17:08:22.687268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#predictions\n\nresults = []\nfor i in range(1000//64 + 1):\n    sample_z_bbox = np.random.normal(0.5, 0.15, (64, 9, 4))\n    sample_z_cls = np.identity(5)[np.random.randint(5, size=(64, 9))]\n    sample_z = np.concatenate([sample_z_bbox, sample_z_cls], axis=-1)\n    results.append(gan.G(sample_z))\n\n","metadata":{"id":"mNczD6sG_nQw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"change = convert_to_cxywh(results[0])\nplot_layouts(change,colors=colors,class_names=class_names)","metadata":{"id":"pnq8N1SJ_nQx","outputId":"7e5298b9-3183-44a3-e596-1b339cba2fa2"},"execution_count":null,"outputs":[]}]}