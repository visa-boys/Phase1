{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras import backend as k\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "publaynet_data = np.load(\"C://Users//kishore prashanth//Downloads//ValidRoomIdsnumpyXcrted.npy\",allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13315, 9, 5)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "publaynet_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MMHSALayer(Layer):\n",
    "    def __init__(self,heads=8):\n",
    "        super(MMHSALayer, self).__init__()\n",
    "        self.heads = heads\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        #print(\"MMSHALAYER build:\",input_shape)\n",
    "        self.model_dim = input_shape[-2]\n",
    "        self.k = self.add_weight(shape=(self.heads,self.model_dim,self.model_dim),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"Key\")\n",
    "        self.q = self.add_weight(shape=(self.heads,self.model_dim,self.model_dim),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"Query\")\n",
    "        self.v = self.add_weight(shape=(self.heads,self.model_dim,self.model_dim),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"Value\")\n",
    "        self.o = self.add_weight(shape=(self.model_dim,self.model_dim*self.heads),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"Heads\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        #print(\"MMSHALAYER call:\",inputs.shape)\n",
    "        mask_shape = inputs.shape[-1]\n",
    "\n",
    "        mask_0 = np.ones((mask_shape,mask_shape))\n",
    "        for i in range(mask_shape):\n",
    "            for j in range(mask_shape):\n",
    "                if (i>j):\n",
    "                    mask_0[i][j]=0\n",
    "        self.mask_0 = tf.constant(mask_0,dtype=tf.float32)\n",
    "\n",
    "        mask_inf = np.zeros((mask_shape,mask_shape))\n",
    "        for i in range(mask_shape):\n",
    "            for j in range(mask_shape):\n",
    "                if (i>j):\n",
    "                    mask_inf[i][j]=-10000000000\n",
    "        self.mask_inf = tf.constant(mask_inf,dtype=tf.float32)\n",
    "\n",
    "        inputs = tf.expand_dims(inputs,1)\n",
    "\n",
    "        key=tf.matmul(self.k,inputs)\n",
    "        que=tf.matmul(self.q,inputs)\n",
    "        val=tf.matmul(self.v,inputs)\n",
    "\n",
    "        Z=tf.matmul(tf.transpose(key,perm=[0,1,3,2]),que)*(1/np.sqrt(self.model_dim))\n",
    "        W=tf.multiply(Z,self.mask_0)\n",
    "        W=tf.add(W,self.mask_inf)\n",
    "        W=tf.keras.activations.softmax(W,axis=1)\n",
    "        W=tf.multiply(W,self.mask_0)\n",
    "        W=tf.matmul(val,W)\n",
    "\n",
    "        W = tf.reshape(W,(inputs.shape[0],self.model_dim*self.heads,mask_shape))\n",
    "\n",
    "        ans = W\n",
    "\n",
    "        ans = tf.matmul(self.o,ans)\n",
    "        ans=tf.expand_dims(ans,0)\n",
    "\n",
    "        ans = tf.squeeze(ans,axis=0)\n",
    "\n",
    "        return ans\n",
    "\n",
    "class Dense2D(Layer):\n",
    "    def __init__(self,units):\n",
    "        super(Dense2D, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        #print(\"Dense2D build:\",input_shape)\n",
    "        input_len = input_shape[-2]\n",
    "\n",
    "        self.w = self.add_weight(shape=(self.units,input_len),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"dense2dw\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        #print(\"Dense2D call:\",inputs)\n",
    "        ans = tf.matmul(self.w,inputs)\n",
    "\n",
    "        return ans\n",
    "\n",
    "class FFLayer(Layer):\n",
    "    def __init__(self, dff=2048, dropout=0.1):\n",
    "        super(FFLayer,self).__init__()\n",
    "        self.dff = dff\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def build(self,input_shape):\n",
    "        #print(\"FFLayer build:\",input_shape)\n",
    "        self.dropout = tf.keras.layers.Dropout(self.dropout)\n",
    "        self.dout = input_shape[-2]\n",
    "\n",
    "        self.w1 = self.add_weight(shape=(self.dff,self.dout),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"ffw1\")\n",
    "        self.w2 = self.add_weight(shape=(self.dout,self.dff),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"ffw2\")\n",
    "        self.b1 = self.add_weight(shape=(self.dff,1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"ffb1\")\n",
    "        self.b2 = self.add_weight(shape=(self.dout,1),\n",
    "                                 initializer='random_normal',\n",
    "                                 trainable=True,\n",
    "                                 name=\"ffb2\")\n",
    "\n",
    "    def call(self,inputs):\n",
    "        #print(\"FFLayer call:\",inputs.shape)\n",
    "        ans = tf.add(tf.matmul(self.w1,inputs),self.b1)\n",
    "        ans = tf.keras.activations.relu(ans)\n",
    "        ans = tf.add(tf.matmul(self.w2,ans),self.b2)\n",
    "\n",
    "        ans = self.dropout(ans)\n",
    "\n",
    "        return ans\n",
    "\n",
    "class ANLayer(Layer):\n",
    "    def __init__(self):\n",
    "        super(ANLayer,self).__init__()\n",
    "        self.Normal = tf.keras.layers.LayerNormalization(axis=1)\n",
    "\n",
    "    def call(self,inputs1,inputs2):\n",
    "        #print(\"ANlayer call:\",inputs1.shape)\n",
    "        #print(\"ANLayer call:\",inputs2.shape)\n",
    "        sum = tf.add(inputs1,inputs2)\n",
    "        ans=self.Normal(sum)\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LTModel(Model):\n",
    "    def __init__(self, input_shape, layers, heads, dff, model_dim, dropout):\n",
    "        super(LTModel, self).__init__()\n",
    "\n",
    "        self.emb = Dense2D(model_dim)\n",
    "\n",
    "        self.SA = []\n",
    "        self.AN1 = []\n",
    "        self.FF = []\n",
    "        self.AN2 = []\n",
    "\n",
    "        for i in range(layers):\n",
    "            self.SA.append(MMHSALayer(heads))\n",
    "            self.AN1.append(ANLayer())\n",
    "            self.FF.append(FFLayer(dff, dropout))\n",
    "            self.AN2.append(ANLayer())\n",
    "\n",
    "        self.deemb = Dense2D(input_shape)\n",
    "        self.sm = tf.keras.layers.Softmax(axis=1)\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.emb(x)\n",
    "\n",
    "        for i in range(len(self.SA)):\n",
    "            y = self.SA[i](x)\n",
    "            x = self.AN1[i](x,y)\n",
    "            y = self.FF[i](x)\n",
    "            x = self.AN2[i](x,y)\n",
    "\n",
    "        x = self.deemb(x)\n",
    "        x = self.sm(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayoutTransformer:\n",
    "\n",
    "    def __init__(self, n_classes, class_labels=None, n_anchors=(32,32), d=512, n_layers=6, n_heads=8, dff=2048, dropout=0.1):\n",
    "        self.n_classes = n_classes+2\n",
    "        self.n_anchors = n_anchors\n",
    "        self.d = d\n",
    "        self.n_layers = n_layers\n",
    "        self.n_heads = n_heads\n",
    "        self.dff = dff\n",
    "        self.dropout = dropout\n",
    "        self.n_row = n_anchors[0]\n",
    "        self.n_col = n_anchors[1]\n",
    "        self.input_dim = 2+n_classes+2*(n_anchors[0]+n_anchors[1])\n",
    "        self.model = LTModel(self.input_dim, model_dim=d, layers=n_layers, heads=n_heads, dff=dff, dropout=dropout)\n",
    "        self.loss_his = []\n",
    "        self.lr_his = []\n",
    "        self.train_data_his = []\n",
    "        if class_labels == None:\n",
    "            self.labels = range(1,n_classes+1)\n",
    "        else:\n",
    "            self.labels = class_labels\n",
    "        self.x_data=[]\n",
    "\n",
    "    def compile(self, lr=1e-5):\n",
    "        self.model.compile(loss=tf.keras.losses.KLDivergence(),\n",
    "                           metrics = [tf.keras.losses.KLDivergence()],\n",
    "                           optimizer = tf.keras.optimizers.Adam(learning_rate=lr))\n",
    "\n",
    "    def build(self):\n",
    "        self.model.build((1,self.input_dim,1))\n",
    "    \n",
    "    def train(self, epochs, batch_size=1, train_data_index=\"All\", rlrop_factor=0.5, rlrop_patience=1000, rlrop_min_delta=0.001):\n",
    "        if train_data_index == \"All\":\n",
    "            train_data_index = range(self.data.shape[0])\n",
    "        rlrop = tf.keras.callbacks.ReduceLROnPlateau(factor=rlrop_factor,patience=rlrop_patience,verbose=1,min_delta=rlrop_min_delta,monitor='kl_divergence')\n",
    "        callbacks = [rlrop]\n",
    "        history = self.model.fit(x=tf.convert_to_tensor(self.x_data[train_data_index]), y=tf.convert_to_tensor(self.y_data[train_data_index]), epochs=epochs, batch_size=batch_size, callbacks=callbacks)\n",
    "        self.loss_his.extend(history.history['loss'])\n",
    "        self.lr_his.extend(history.history['lr'])\n",
    "        for i in range(epochs):\n",
    "            self.train_data_his.append(len(train_data_index))\n",
    "\n",
    "    def load_weights(self, folder_path, filename):\n",
    "        self.build()\n",
    "        self.model.load_weights(folder_path + '/' + str(filename) + '.h5')\n",
    "        his = json.loads(open(folder_path + '/' + str(filename) + '.json').read())\n",
    "\n",
    "        self.loss_his = his['loss']\n",
    "        self.train_data_his = his['data']\n",
    "        self.lr_his = his['lr']\n",
    "\n",
    "\n",
    "    def save_weights(self, folder_path, filename):\n",
    "        his = json.dumps({'loss':list(np.array(self.loss_his,dtype='float')),'data':list(np.array(self.train_data_his,dtype='float')),'lr':list(np.array(self.lr_his,dtype='float'))})\n",
    "        open(folder_path + '/' + str(filename) + '.json','w').write(his)\n",
    "        self.model.save_weights(folder_path + '/' + str(filename) + '.h5')\n",
    "\n",
    "    def load_data(self, data, rows, cols, e=0.1):\n",
    "\n",
    "        self.orig_data = np.array(data,dtype='float32')\n",
    "        data = np.array(data,dtype='float32')\n",
    "\n",
    "        data[:,:,1] = data[:,:,1]*(cols*(self.n_col-1)) \n",
    "        data[:,:,2] = data[:,:,2]*(rows*(self.n_row-1))\n",
    "        data[:,:,3] = data[:,:,3]*(cols*(self.n_col-1))\n",
    "        data[:,:,4] = data[:,:,4]*(rows*(self.n_row-1))\n",
    "\n",
    "        data = np.array(data,dtype='int')\n",
    "\n",
    "        # Sorting\n",
    "        for i in range(data.shape[0]):\n",
    "            box_num = data[i].shape[0]\n",
    "\n",
    "            c=0\n",
    "            for j in data[i]:\n",
    "                if j[3]==0 and j[4]==0:\n",
    "                    break\n",
    "                c = c+1 #total number of valid boxes\n",
    "\n",
    "            order = [*list(data[i][0:c,3].argsort()),*range(c,box_num)] # 4 Width (Col)\n",
    "            data[i] = np.array(data[i,order])\n",
    "            order = [*list(data[i][0:c,4].argsort()),*range(c,box_num)] # 3 Height (Row)\n",
    "            data[i] = np.array(data[i,order])\n",
    "            order = [*list(data[i][0:c,1].argsort()),*range(c,box_num)] # 2 X-Pos (Col)\n",
    "            data[i] = np.array(data[i,order])\n",
    "            order = [*list(data[i][0:c,2].argsort()),*range(c,box_num)] # 1 Y-Pos (Row)\n",
    "            data[i] = np.array(data[i,order])\n",
    "\n",
    "        self.data = data\n",
    "\n",
    "        # One hot encoding\n",
    "        onehot_data = []\n",
    "\n",
    "        for doc in data:\n",
    "            cur_data = []\n",
    "            for box in doc:\n",
    "                cur_cur_data = list(np.zeros(self.input_dim))\n",
    "                cur_cur_data[box[0]] = 1\n",
    "                cur_cur_data[box[1]+self.n_classes] = 1\n",
    "                cur_cur_data[box[2]+self.n_classes+self.n_col] = 1\n",
    "                cur_cur_data[box[3]+self.n_classes+self.n_col+self.n_row] = 1\n",
    "                cur_cur_data[box[4]+self.n_classes+self.n_col*2+self.n_row] = 1\n",
    "                cur_data.append(cur_cur_data)\n",
    "            onehot_data.append(cur_data)\n",
    "\n",
    "        self.onehot_data = np.array(onehot_data, dtype='float32') ######\n",
    "\n",
    "        # x_data with <bos> and y_data with <eos>\n",
    "        x_data = []\n",
    "        y_data = []\n",
    "\n",
    "        for doc in onehot_data:\n",
    "            bos = list(np.zeros(self.input_dim))\n",
    "            bos[0]=1\n",
    "            x = [bos,*doc]\n",
    "            x = np.array(x).T\n",
    "            x_data.append(x)\n",
    "\n",
    "            eos = list(np.zeros(self.input_dim))\n",
    "            eos[self.n_classes-1] = 1\n",
    "            y = [*doc,eos]\n",
    "            for box in y:\n",
    "                for k in range(0, self.n_classes):\n",
    "                    box[k] = (1 - e) * box[k] + e / self.n_classes\n",
    "                for k in range(self.n_classes, self.n_classes+self.n_col):\n",
    "                    box[k] = (1 - e) * box[k] + e / self.n_col\n",
    "                for k in range(self.n_classes+self.n_col, self.n_classes+self.n_col+self.n_row):\n",
    "                    box[k] = (1 - e) * box[k] + e / self.n_row\n",
    "                for k in range(self.n_classes+self.n_col+self.n_row, self.n_classes+2*self.n_col+self.n_row):\n",
    "                    box[k] = (1 - e) * box[k] + e / self.n_col\n",
    "                for k in range(self.n_classes+2*self.n_col+self.n_row, self.n_classes+2*self.n_col+2*self.n_row):\n",
    "                    box[k] = (1 - e) * box[k] + e / self.n_row\n",
    "            y = np.array(y).T\n",
    "            y_data.append(y)\n",
    "\n",
    "        self.x_data = np.array(x_data,dtype=\"float32\")\n",
    "        self.y_data = np.array(y_data,dtype=\"float32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "publay_model = LayoutTransformer(n_classes=11, class_labels=[\"None\",\"Living room\",\"Master room\",\"Kitchen\",\"Bathroom\",\"Dining room\",\n",
    "              \"Child room\",\"Study room\",\"Second room\",\"Guest room\",\"Balcony\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "publay_model.load_data(publaynet_data[0:13315],rows=1,cols=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = publay_model\n",
    "\n",
    "epochs = 1\n",
    "lrate = 1e-5\n",
    "\n",
    "min_delta = 0.001\n",
    "patience = 20\n",
    "factor = 0.95\n",
    "\n",
    "count = 0\n",
    "model.compile(lr=lrate)\n",
    "\n",
    "for i in range(epochs):\n",
    "    gc.collect()\n",
    "    k.clear_session()\n",
    "    try:\n",
    "        if model.loss_his[-2]-model.loss_his[-1]<min_delta:\n",
    "            count = count+1\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    if count==patience:\n",
    "        count = 0\n",
    "        lrate = lrate*factor\n",
    "        model.compile(lr=lrate)\n",
    "\n",
    "    model.train(epochs=1, batch_size=1, train_data_index='All')\n",
    "    if i>0 and i%5==0:\n",
    "      model.save_weights('./','model'+str(i+1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
